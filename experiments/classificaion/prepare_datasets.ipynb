{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-17T13:30:16.935192Z",
     "end_time": "2023-04-17T13:30:18.004530Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../Fedot.Industrial')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from core.architecture.datasets.splitters import get_dataset_mean_std, split_data, undersampling, dataset_info\n",
    "\n",
    "DATASETS_ROOT = '/media/n31v/data/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST\n",
    "mean=(0.13066,), std=(0.3081,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:06<00:00, 8974.01it/s]\n",
      "100%|██████████| 60000/60000 [00:04<00:00, 14236.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5923 samples.\n",
      "Class 1 contains 6742 samples.\n",
      "Class 2 contains 5958 samples.\n",
      "Class 3 contains 6131 samples.\n",
      "Class 4 contains 5842 samples.\n",
      "Class 5 contains 5421 samples.\n",
      "Class 6 contains 5918 samples.\n",
      "Class 7 contains 6265 samples.\n",
      "Class 8 contains 5851 samples.\n",
      "Class 9 contains 5949 samples.\n",
      "mean = (0.13066047797803165,), std = (0.3081078048756658,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(mnist_ds)\n",
    "dataset_info(mnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_ds = undersampling(mnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(mnist_ds, 2)\n",
    "    folds.append(np.array([mnist_ds.indices[f1], mnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'MNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'MNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FashionMNIST\n",
    "mean=(0.286,), std=(0.353,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fmnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "mean, std = get_dataset_mean_std(fmnist_ds)\n",
    "dataset_info(fmnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fmnist_ds = undersampling(fmnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(fmnist_ds, 2)\n",
    "    folds.append(np.array([fmnist_ds.indices[f1], fmnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR10\n",
    "mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:06<00:00, 7721.50it/s]\n",
      "100%|██████████| 50000/50000 [00:04<00:00, 11767.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5000 samples.\n",
      "Class 1 contains 5000 samples.\n",
      "Class 2 contains 5000 samples.\n",
      "Class 3 contains 5000 samples.\n",
      "Class 4 contains 5000 samples.\n",
      "Class 5 contains 5000 samples.\n",
      "Class 6 contains 5000 samples.\n",
      "Class 7 contains 5000 samples.\n",
      "Class 8 contains 5000 samples.\n",
      "Class 9 contains 5000 samples.\n",
      "mean = (0.4913996927399561, 0.4821584222899936, 0.4465309280202538), std = (0.24703223297351337, 0.2434851287896555, 0.26158784042441807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(cifar10_ds)\n",
    "dataset_info(cifar10_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = []\n",
    "for i in range(5):\n",
    "    folds.append(np.array(split_data(cifar10_ds, 2)))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds.npy'))\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=cifar10_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=cifar10_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImageFolder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def check_dataset(dataset: str):\n",
    "    folds = np.load(os.path.join(DATASETS_ROOT, dataset, 'folds.npy'))\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    for i in range(5):\n",
    "        fold1 = Subset(dataset=ds, indices=folds[i, 0, :])\n",
    "        dataset_info(fold1, verbose=True)\n",
    "        fold2 = Subset(dataset=ds, indices=folds[i, 1, :])\n",
    "        dataset_info(fold2, verbose=True)\n",
    "\n",
    "def prepare_dataset(dataset: str, check: bool = True, n: Optional[int] = None):\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    classes = dataset_info(ds)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('dataset info:')\n",
    "    print('------------------------------------------------------------------')\n",
    "    idx_to_class = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    for k, v in classes.items():\n",
    "        print(f\"Class {k} {idx_to_class[k]} contains {v} samples.\")\n",
    "    print(f'{mean=}, {std=}')\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('undersamling...')\n",
    "    print('------------------------------------------------------------------')\n",
    "    if n is None:\n",
    "        n = min(classes.values())\n",
    "        n = n if n % 2 == 0 else n - 1\n",
    "    ds = undersampling(ds, n=n)\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    print(f'{mean=}, {std=}')\n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        f1, f2 = split_data(ds, 2)\n",
    "        folds.append(np.array([ds.indices[f1], ds.indices[f2]]))\n",
    "    folds = np.array(folds)\n",
    "    np.save(os.path.join(DATASETS_ROOT, dataset, 'folds'), folds)\n",
    "    print(folds.shape)\n",
    "    if check:\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('checking dataset...')\n",
    "        print('------------------------------------------------------------------')\n",
    "        check_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T13:30:18.010534Z",
     "end_time": "2023-04-17T13:30:18.011991Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land-Use_Scene_Classification\n",
    "mean=(0.462, 0.471, 0.440), std=(0.287, 0.279, 0.269)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'Land-Use_Scene_Classification/images'), n=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T17:14:53.345598Z",
     "end_time": "2023-04-12T17:17:29.451609Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals 200x200\n",
    "mean=(0.54, 0.61, 0.51), std=(0.22, 0.23, 0.23)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30231/30231 [10:39<00:00, 47.28it/s] \n",
      "100%|██████████| 30231/30231 [00:40<00:00, 749.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "dataset info:\n",
      "------------------------------------------------------------------\n",
      "Class 0 01_Almandin contains 1257 samples.\n",
      "Class 1 02_Amazonit contains 1349 samples.\n",
      "Class 2 03_Apatit contains 1665 samples.\n",
      "Class 3 04_Barit contains 1434 samples.\n",
      "Class 4 05_Berill contains 1459 samples.\n",
      "Class 5 06_Biotit contains 1371 samples.\n",
      "Class 6 07_Granat contains 1650 samples.\n",
      "Class 7 08_Diopsit contains 1499 samples.\n",
      "Class 8 09_Gold contains 1369 samples.\n",
      "Class 9 11_Quarz_1 contains 1426 samples.\n",
      "Class 10 13_Kianit contains 1161 samples.\n",
      "Class 11 14_Kordierit contains 1619 samples.\n",
      "Class 12 16_Magnetit contains 1036 samples.\n",
      "Class 13 17_Microclin contains 1562 samples.\n",
      "Class 14 18_Muscovit contains 1676 samples.\n",
      "Class 15 19_Olivin contains 1530 samples.\n",
      "Class 16 20_Pirit contains 1148 samples.\n",
      "Class 17 21_Fluorit contains 1344 samples.\n",
      "Class 18 22_Chromshpinelid contains 1589 samples.\n",
      "Class 19 23_Cavorit contains 1286 samples.\n",
      "Class 20 24_Shpinel contains 1801 samples.\n",
      "mean=(0.5393682923895768, 0.6117763395643742, 0.5149275767261645), std=(0.21992925305277355, 0.23249561745764574, 0.22548122486562205)\n",
      "------------------------------------------------------------------\n",
      "undersamling...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30231/30231 [00:21<00:00, 1433.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of any class 200 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [00:03<00:00, 1208.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=(0.532572816544494, 0.6064249081435182, 0.5076473054673534), std=(0.21908636753532626, 0.23285019825379735, 0.2240093823931045)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [00:03<00:00, 1287.14it/s]\n",
      "100%|██████████| 4200/4200 [00:03<00:00, 1372.56it/s]\n",
      "100%|██████████| 4200/4200 [00:03<00:00, 1356.39it/s]\n",
      "100%|██████████| 4200/4200 [00:03<00:00, 1109.02it/s]\n",
      "100%|██████████| 4200/4200 [00:03<00:00, 1264.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 2100)\n",
      "------------------------------------------------------------------\n",
      "checking dataset...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1431.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1189.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1521.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1431.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1245.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1394.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1487.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1389.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1453.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:01<00:00, 1448.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'minerals_21_200'), n=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T13:30:18.013448Z",
     "end_time": "2023-04-17T13:42:34.171581Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
