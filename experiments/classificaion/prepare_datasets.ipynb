{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-12T17:14:52.307190Z",
     "end_time": "2023-04-12T17:14:53.337206Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../Fedot.Industrial')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from core.architecture.datasets.splitters import get_dataset_mean_std, split_data, undersampling, dataset_info\n",
    "\n",
    "DATASETS_ROOT = '/media/n31v/data/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST\n",
    "mean=(0.13066,), std=(0.3081,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:06<00:00, 8974.01it/s]\n",
      "100%|██████████| 60000/60000 [00:04<00:00, 14236.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5923 samples.\n",
      "Class 1 contains 6742 samples.\n",
      "Class 2 contains 5958 samples.\n",
      "Class 3 contains 6131 samples.\n",
      "Class 4 contains 5842 samples.\n",
      "Class 5 contains 5421 samples.\n",
      "Class 6 contains 5918 samples.\n",
      "Class 7 contains 6265 samples.\n",
      "Class 8 contains 5851 samples.\n",
      "Class 9 contains 5949 samples.\n",
      "mean = (0.13066047797803165,), std = (0.3081078048756658,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(mnist_ds)\n",
    "dataset_info(mnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_ds = undersampling(mnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(mnist_ds, 2)\n",
    "    folds.append(np.array([mnist_ds.indices[f1], mnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'MNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'MNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FashionMNIST\n",
    "mean=(0.286,), std=(0.353,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fmnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "mean, std = get_dataset_mean_std(fmnist_ds)\n",
    "dataset_info(fmnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fmnist_ds = undersampling(fmnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(fmnist_ds, 2)\n",
    "    folds.append(np.array([fmnist_ds.indices[f1], fmnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR10\n",
    "mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:06<00:00, 7721.50it/s]\n",
      "100%|██████████| 50000/50000 [00:04<00:00, 11767.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5000 samples.\n",
      "Class 1 contains 5000 samples.\n",
      "Class 2 contains 5000 samples.\n",
      "Class 3 contains 5000 samples.\n",
      "Class 4 contains 5000 samples.\n",
      "Class 5 contains 5000 samples.\n",
      "Class 6 contains 5000 samples.\n",
      "Class 7 contains 5000 samples.\n",
      "Class 8 contains 5000 samples.\n",
      "Class 9 contains 5000 samples.\n",
      "mean = (0.4913996927399561, 0.4821584222899936, 0.4465309280202538), std = (0.24703223297351337, 0.2434851287896555, 0.26158784042441807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(cifar10_ds)\n",
    "dataset_info(cifar10_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = []\n",
    "for i in range(5):\n",
    "    folds.append(np.array(split_data(cifar10_ds, 2)))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds.npy'))\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=cifar10_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=cifar10_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImageFolder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def check_dataset(dataset: str):\n",
    "    folds = np.load(os.path.join(DATASETS_ROOT, dataset, 'folds.npy'))\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    for i in range(5):\n",
    "        fold1 = Subset(dataset=ds, indices=folds[i, 0, :])\n",
    "        dataset_info(fold1, verbose=True)\n",
    "        fold2 = Subset(dataset=ds, indices=folds[i, 1, :])\n",
    "        dataset_info(fold2, verbose=True)\n",
    "\n",
    "def prepare_dataset(dataset: str, check: bool = True, n: Optional[int] = None):\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    classes = dataset_info(ds)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('dataset info:')\n",
    "    print('------------------------------------------------------------------')\n",
    "    idx_to_class = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    for k, v in classes.items():\n",
    "        print(f\"Class {k} {idx_to_class[k]} contains {v} samples.\")\n",
    "    print(f'{mean=}, {std=}')\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('undersamling...')\n",
    "    print('------------------------------------------------------------------')\n",
    "    if n is None:\n",
    "        n = min(classes.values())\n",
    "        n = n if n % 2 == 0 else n - 1\n",
    "    ds = undersampling(ds, n=n)\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    print(f'{mean=}, {std=}')\n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        f1, f2 = split_data(ds, 2)\n",
    "        folds.append(np.array([ds.indices[f1], ds.indices[f2]]))\n",
    "    folds = np.array(folds)\n",
    "    np.save(os.path.join(DATASETS_ROOT, dataset, 'folds'), folds)\n",
    "    print(folds.shape)\n",
    "    if check:\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('checking dataset...')\n",
    "        print('------------------------------------------------------------------')\n",
    "        check_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T17:14:53.343064Z",
     "end_time": "2023-04-12T17:14:53.344202Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land-Use_Scene_Classification\n",
    "mean=(0.462, 0.471, 0.440), std=(0.287, 0.279, 0.269)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'Land-Use_Scene_Classification/images'), n=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T17:14:53.345598Z",
     "end_time": "2023-04-12T17:17:29.451609Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals 200x200\n",
    "mean=(0.54, 0.61, 0.51), std=(0.22, 0.23, 0.23)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'minerals_21_200'), n=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T17:17:29.451375Z",
     "end_time": "2023-04-12T17:19:41.259642Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
