{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-06T14:31:09.900265Z",
     "end_time": "2023-04-06T14:31:10.879434Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../Fedot.Industrial')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from core.architecture.datasets.splitters import get_dataset_mean_std, split_data, undersampling, dataset_info\n",
    "\n",
    "DATASETS_ROOT = '/media/n31v/data/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST\n",
    "mean=(0.13066,), std=(0.3081,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:06<00:00, 8974.01it/s]\n",
      "100%|██████████| 60000/60000 [00:04<00:00, 14236.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5923 samples.\n",
      "Class 1 contains 6742 samples.\n",
      "Class 2 contains 5958 samples.\n",
      "Class 3 contains 6131 samples.\n",
      "Class 4 contains 5842 samples.\n",
      "Class 5 contains 5421 samples.\n",
      "Class 6 contains 5918 samples.\n",
      "Class 7 contains 6265 samples.\n",
      "Class 8 contains 5851 samples.\n",
      "Class 9 contains 5949 samples.\n",
      "mean = (0.13066047797803165,), std = (0.3081078048756658,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(mnist_ds)\n",
    "dataset_info(mnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_ds = undersampling(mnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(mnist_ds, 2)\n",
    "    folds.append(np.array([mnist_ds.indices[f1], mnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'MNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'MNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FashionMNIST\n",
    "mean=(0.286,), std=(0.353,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fmnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "mean, std = get_dataset_mean_std(fmnist_ds)\n",
    "dataset_info(fmnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fmnist_ds = undersampling(fmnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(fmnist_ds, 2)\n",
    "    folds.append(np.array([fmnist_ds.indices[f1], fmnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR10\n",
    "mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:06<00:00, 7721.50it/s]\n",
      "100%|██████████| 50000/50000 [00:04<00:00, 11767.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5000 samples.\n",
      "Class 1 contains 5000 samples.\n",
      "Class 2 contains 5000 samples.\n",
      "Class 3 contains 5000 samples.\n",
      "Class 4 contains 5000 samples.\n",
      "Class 5 contains 5000 samples.\n",
      "Class 6 contains 5000 samples.\n",
      "Class 7 contains 5000 samples.\n",
      "Class 8 contains 5000 samples.\n",
      "Class 9 contains 5000 samples.\n",
      "mean = (0.4913996927399561, 0.4821584222899936, 0.4465309280202538), std = (0.24703223297351337, 0.2434851287896555, 0.26158784042441807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(cifar10_ds)\n",
    "dataset_info(cifar10_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = []\n",
    "for i in range(5):\n",
    "    folds.append(np.array(split_data(cifar10_ds, 2)))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds.npy'))\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=cifar10_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=cifar10_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImageFolder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def check_dataset(dataset: str):\n",
    "    folds = np.load(os.path.join(DATASETS_ROOT, dataset, 'folds.npy'))\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    for i in range(5):\n",
    "        fold1 = Subset(dataset=ds, indices=folds[i, 0, :])\n",
    "        dataset_info(fold1, verbose=True)\n",
    "        fold2 = Subset(dataset=ds, indices=folds[i, 1, :])\n",
    "        dataset_info(fold2, verbose=True)\n",
    "\n",
    "def prepare_dataset(dataset: str, check: bool = True, n: Optional[int] = None):\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    classes = dataset_info(ds)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('dataset info:')\n",
    "    print('------------------------------------------------------------------')\n",
    "    idx_to_class = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    for k, v in classes.items():\n",
    "        print(f\"Class {k} {idx_to_class[k]} contains {v} samples.\")\n",
    "    print(f'{mean=}, {std=}')\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('undersamling...')\n",
    "    print('------------------------------------------------------------------')\n",
    "    if n is None:\n",
    "        n = min(classes.values())\n",
    "        n = n if n % 2 == 0 else n - 1\n",
    "    ds = undersampling(ds, n=n)\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    print(f'{mean=}, {std=}')\n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        f1, f2 = split_data(ds, 2)\n",
    "        folds.append(np.array([ds.indices[f1], ds.indices[f2]]))\n",
    "    folds = np.array(folds)\n",
    "    np.save(os.path.join(DATASETS_ROOT, dataset, 'folds'), folds)\n",
    "    print(folds.shape)\n",
    "    if check:\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('checking dataset...')\n",
    "        print('------------------------------------------------------------------')\n",
    "        check_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T14:57:33.669192Z",
     "end_time": "2023-04-06T14:57:33.715555Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Land-Use_Scene_Classification\n",
    "mean=(0.458, 0.467, 0.437), std=(0.289, 0.281, 0.270)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:20<00:00, 509.58it/s]\n",
      "100%|██████████| 10500/10500 [00:19<00:00, 539.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "dataset info:\n",
      "------------------------------------------------------------------\n",
      "Class 0 agricultural contains 500 samples.\n",
      "Class 1 airplane contains 500 samples.\n",
      "Class 2 baseballdiamond contains 500 samples.\n",
      "Class 3 beach contains 500 samples.\n",
      "Class 4 buildings contains 500 samples.\n",
      "Class 5 chaparral contains 500 samples.\n",
      "Class 6 denseresidential contains 500 samples.\n",
      "Class 7 forest contains 500 samples.\n",
      "Class 8 freeway contains 500 samples.\n",
      "Class 9 golfcourse contains 500 samples.\n",
      "Class 10 harbor contains 500 samples.\n",
      "Class 11 intersection contains 500 samples.\n",
      "Class 12 mediumresidential contains 500 samples.\n",
      "Class 13 mobilehomepark contains 500 samples.\n",
      "Class 14 overpass contains 500 samples.\n",
      "Class 15 parkinglot contains 500 samples.\n",
      "Class 16 river contains 500 samples.\n",
      "Class 17 runway contains 500 samples.\n",
      "Class 18 sparseresidential contains 500 samples.\n",
      "Class 19 storagetanks contains 500 samples.\n",
      "Class 20 tenniscourt contains 500 samples.\n",
      "mean=(0.4592847087534194, 0.4682720124741867, 0.43708201167849886), std=(0.2881617344227249, 0.2800573627702071, 0.26914809932578093)\n",
      "------------------------------------------------------------------\n",
      "undersamling...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10500/10500 [00:20<00:00, 518.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of any class 200 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [00:08<00:00, 507.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean=(0.45834349999101315, 0.4672601771127858, 0.4368523198774913), std=(0.2893816882307876, 0.2808980277810426, 0.2702369471265301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [00:07<00:00, 567.74it/s]\n",
      "100%|██████████| 4200/4200 [00:07<00:00, 557.37it/s]\n",
      "100%|██████████| 4200/4200 [00:07<00:00, 568.31it/s]\n",
      "100%|██████████| 4200/4200 [00:07<00:00, 554.09it/s]\n",
      "100%|██████████| 4200/4200 [00:07<00:00, 565.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 2100)\n",
      "------------------------------------------------------------------\n",
      "checking dataset...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 575.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 582.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 562.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 576.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 568.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 561.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 568.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 581.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:03<00:00, 547.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2100/2100 [00:04<00:00, 520.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 100 samples.\n",
      "Class 1 contains 100 samples.\n",
      "Class 2 contains 100 samples.\n",
      "Class 3 contains 100 samples.\n",
      "Class 4 contains 100 samples.\n",
      "Class 5 contains 100 samples.\n",
      "Class 6 contains 100 samples.\n",
      "Class 7 contains 100 samples.\n",
      "Class 8 contains 100 samples.\n",
      "Class 9 contains 100 samples.\n",
      "Class 10 contains 100 samples.\n",
      "Class 11 contains 100 samples.\n",
      "Class 12 contains 100 samples.\n",
      "Class 13 contains 100 samples.\n",
      "Class 14 contains 100 samples.\n",
      "Class 15 contains 100 samples.\n",
      "Class 16 contains 100 samples.\n",
      "Class 17 contains 100 samples.\n",
      "Class 18 contains 100 samples.\n",
      "Class 19 contains 100 samples.\n",
      "Class 20 contains 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset(os.path.join(DATASETS_ROOT, 'Land-Use_Scene_Classification/images'), n=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T14:58:15.312114Z",
     "end_time": "2023-04-06T15:00:38.619575Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals 200x200\n",
    "mean=(0.291, 0.4226, 0.4654), std=(0.2227, 0.2412, 0.3168)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
