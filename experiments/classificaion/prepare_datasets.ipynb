{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../Fedot.Industrial')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from core.architecture.datasets.splitters import get_dataset_mean_std, split_data, undersampling, dataset_info\n",
    "\n",
    "DATASETS_ROOT = '/media/n31v/data/datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MNIST\n",
    "mean=(0.13066,), std=(0.3081,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:06<00:00, 8974.01it/s]\n",
      "100%|██████████| 60000/60000 [00:04<00:00, 14236.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5923 samples.\n",
      "Class 1 contains 6742 samples.\n",
      "Class 2 contains 5958 samples.\n",
      "Class 3 contains 6131 samples.\n",
      "Class 4 contains 5842 samples.\n",
      "Class 5 contains 5421 samples.\n",
      "Class 6 contains 5918 samples.\n",
      "Class 7 contains 6265 samples.\n",
      "Class 8 contains 5851 samples.\n",
      "Class 9 contains 5949 samples.\n",
      "mean = (0.13066047797803165,), std = (0.3081078048756658,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(mnist_ds)\n",
    "dataset_info(mnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_ds = undersampling(mnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(mnist_ds, 2)\n",
    "    folds.append(np.array([mnist_ds.indices[f1], mnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'MNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'MNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = MNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FashionMNIST\n",
    "mean=(0.286,), std=(0.353,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "fmnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "mean, std = get_dataset_mean_std(fmnist_ds)\n",
    "dataset_info(fmnist_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fmnist_ds = undersampling(fmnist_ds, n=5000)\n",
    "\n",
    "folds = []\n",
    "for i in range(5):\n",
    "    f1, f2 = split_data(fmnist_ds, 2)\n",
    "    folds.append(np.array([fmnist_ds.indices[f1], fmnist_ds.indices[f2]]))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'FashionMNIST', 'folds.npy'))\n",
    "\n",
    "mnist_ds = FashionMNIST(\n",
    "    root=DATASETS_ROOT,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=mnist_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=mnist_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CIFAR10\n",
    "mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:06<00:00, 7721.50it/s]\n",
      "100%|██████████| 50000/50000 [00:04<00:00, 11767.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 5000 samples.\n",
      "Class 1 contains 5000 samples.\n",
      "Class 2 contains 5000 samples.\n",
      "Class 3 contains 5000 samples.\n",
      "Class 4 contains 5000 samples.\n",
      "Class 5 contains 5000 samples.\n",
      "Class 6 contains 5000 samples.\n",
      "Class 7 contains 5000 samples.\n",
      "Class 8 contains 5000 samples.\n",
      "Class 9 contains 5000 samples.\n",
      "mean = (0.4913996927399561, 0.4821584222899936, 0.4465309280202538), std = (0.24703223297351337, 0.2434851287896555, 0.26158784042441807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "mean, std = get_dataset_mean_std(cifar10_ds)\n",
    "dataset_info(cifar10_ds)\n",
    "print(f'{mean=}, {std=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = []\n",
    "for i in range(5):\n",
    "    folds.append(np.array(split_data(cifar10_ds, 2)))\n",
    "folds = np.array(folds)\n",
    "np.save(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds'), folds)\n",
    "print(folds.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = np.load(os.path.join(DATASETS_ROOT, 'CIFAR10', 'folds.npy'))\n",
    "\n",
    "cifar10_ds = CIFAR10(\n",
    "    root=os.path.join(DATASETS_ROOT, 'CIFAR10'),\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    fold1 = Subset(dataset=cifar10_ds, indices=folds[i, 0, :])\n",
    "    dataset_info(fold1)\n",
    "    fold2 = Subset(dataset=cifar10_ds, indices=folds[i, 1, :])\n",
    "    dataset_info(fold2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ImageFolder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "def check_dataset(dataset: str):\n",
    "    folds = np.load(os.path.join(DATASETS_ROOT, dataset, 'folds.npy'))\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    for i in range(5):\n",
    "        fold1 = Subset(dataset=ds, indices=folds[i, 0, :])\n",
    "        dataset_info(fold1, verbose=True)\n",
    "        fold2 = Subset(dataset=ds, indices=folds[i, 1, :])\n",
    "        dataset_info(fold2, verbose=True)\n",
    "\n",
    "def prepare_dataset(dataset: str, check: bool = True):\n",
    "    ds = ImageFolder(\n",
    "        root=os.path.join(DATASETS_ROOT, dataset),\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    mean, std = get_dataset_mean_std(ds)\n",
    "    classes = dataset_info(ds)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('dataset info:')\n",
    "    print('------------------------------------------------------------------')\n",
    "    idx_to_class = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    for k, v in classes.items():\n",
    "        print(f\"Class {k} {idx_to_class[k]} contains {v} samples.\")\n",
    "    print(f'{mean=}, {std=}')\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('undersamling...')\n",
    "    print('------------------------------------------------------------------')\n",
    "    n = min(classes.values())\n",
    "    n = n if n % 2 == 0 else n - 1\n",
    "    ds = undersampling(ds, n=n)\n",
    "    folds = []\n",
    "    for i in range(5):\n",
    "        f1, f2 = split_data(ds, 2)\n",
    "        folds.append(np.array([ds.indices[f1], ds.indices[f2]]))\n",
    "    folds = np.array(folds)\n",
    "    np.save(os.path.join(DATASETS_ROOT, dataset, 'folds'), folds)\n",
    "    print(folds.shape)\n",
    "    if check:\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('checking dataset...')\n",
    "        print('------------------------------------------------------------------')\n",
    "        check_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals\n",
    "mean=(0.291, 0.4226, 0.4654), std=(0.2227, 0.2412, 0.3168)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset('minerals')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals (150x150)\n",
    "mean=(0.4186, 0.4301, 0.4217), std=(0.228, 0.217, 0.2543)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset('minerals_classification')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minerals 200\n",
    "mean=(0.444, 0.562, 0.556), std=(0.207, 0.235, 0.231)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prepare_dataset('minerals200')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18495/18495 [02:01<00:00, 152.27it/s] \n",
      "100%|██████████| 18495/18495 [00:14<00:00, 1262.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "dataset info:\n",
      "------------------------------------------------------------------\n",
      "Class 0 01_Almandin contains 624 samples.\n",
      "Class 1 02_Amazonit contains 604 samples.\n",
      "Class 2 03_Apatit contains 829 samples.\n",
      "Class 3 04_Barit contains 782 samples.\n",
      "Class 4 05_Berill contains 660 samples.\n",
      "Class 5 06_Biotit contains 795 samples.\n",
      "Class 6 07_Granat contains 888 samples.\n",
      "Class 7 08_Diopsit contains 633 samples.\n",
      "Class 8 09_Gold contains 870 samples.\n",
      "Class 9 10_Calcit contains 796 samples.\n",
      "Class 10 11_Quarz_1 contains 746 samples.\n",
      "Class 11 12_Quarz_2 contains 856 samples.\n",
      "Class 12 13_Kianit contains 635 samples.\n",
      "Class 13 14_Kordierit contains 767 samples.\n",
      "Class 14 15_Korund contains 667 samples.\n",
      "Class 15 16_Magnetit contains 575 samples.\n",
      "Class 16 17_Microclin contains 799 samples.\n",
      "Class 17 18_Muscovit contains 851 samples.\n",
      "Class 18 19_Olivin contains 922 samples.\n",
      "Class 19 20_Pirit contains 670 samples.\n",
      "Class 20 21_Fluorit contains 831 samples.\n",
      "Class 21 22_Chromshpinelid contains 960 samples.\n",
      "Class 22 23_Cavorit contains 769 samples.\n",
      "Class 23 24_Shpinel contains 966 samples.\n",
      "mean=(0.4818028474893227, 0.5485772118990618, 0.43955665981383507), std=(0.20764559475555408, 0.2265962756012177, 0.20003594733727412)\n",
      "------------------------------------------------------------------\n",
      "undersamling...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18495/18495 [00:14<00:00, 1279.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of any class 574 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13776/13776 [00:11<00:00, 1196.29it/s]\n",
      "100%|██████████| 13776/13776 [00:11<00:00, 1195.75it/s]\n",
      "100%|██████████| 13776/13776 [00:11<00:00, 1169.62it/s]\n",
      "100%|██████████| 13776/13776 [00:12<00:00, 1083.53it/s]\n",
      "100%|██████████| 13776/13776 [00:11<00:00, 1220.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 6888)\n",
      "------------------------------------------------------------------\n",
      "checking dataset...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1219.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1211.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1224.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1201.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1215.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1211.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1229.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1216.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1234.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6888/6888 [00:05<00:00, 1172.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 contains 287 samples.\n",
      "Class 1 contains 287 samples.\n",
      "Class 2 contains 287 samples.\n",
      "Class 3 contains 287 samples.\n",
      "Class 4 contains 287 samples.\n",
      "Class 5 contains 287 samples.\n",
      "Class 6 contains 287 samples.\n",
      "Class 7 contains 287 samples.\n",
      "Class 8 contains 287 samples.\n",
      "Class 9 contains 287 samples.\n",
      "Class 10 contains 287 samples.\n",
      "Class 11 contains 287 samples.\n",
      "Class 12 contains 287 samples.\n",
      "Class 13 contains 287 samples.\n",
      "Class 14 contains 287 samples.\n",
      "Class 15 contains 287 samples.\n",
      "Class 16 contains 287 samples.\n",
      "Class 17 contains 287 samples.\n",
      "Class 18 contains 287 samples.\n",
      "Class 19 contains 287 samples.\n",
      "Class 20 contains 287 samples.\n",
      "Class 21 contains 287 samples.\n",
      "Class 22 contains 287 samples.\n",
      "Class 23 contains 287 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset('New_dataset_big')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9617/9617 [00:15<00:00, 606.08it/s]\n",
      "100%|██████████| 9617/9617 [00:10<00:00, 957.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "dataset info:\n",
      "------------------------------------------------------------------\n",
      "Class 0 01_Almandin contains 305 samples.\n",
      "Class 1 02_Amazonit contains 318 samples.\n",
      "Class 2 03_Apatit contains 354 samples.\n",
      "Class 3 04_Barit contains 337 samples.\n",
      "Class 4 05_Berill contains 368 samples.\n",
      "Class 5 06_Biotit contains 362 samples.\n",
      "Class 6 07_Granat contains 362 samples.\n",
      "Class 7 08_Diopsit contains 406 samples.\n",
      "Class 8 09_Gold contains 334 samples.\n",
      "Class 9 10_Calcit contains 368 samples.\n",
      "Class 10 11_Quarz_1 contains 388 samples.\n",
      "Class 11 12_Quarz_2 contains 424 samples.\n",
      "Class 12 13_Kianit contains 391 samples.\n",
      "Class 13 14_Kordierit contains 446 samples.\n",
      "Class 14 15_Korund contains 397 samples.\n",
      "Class 15 16_Magnetit contains 356 samples.\n",
      "Class 16 17_Microclin contains 406 samples.\n",
      "Class 17 18_Muscovit contains 608 samples.\n",
      "Class 18 19_Olivin contains 471 samples.\n",
      "Class 19 20_Pirit contains 411 samples.\n",
      "Class 20 21_Fluorit contains 451 samples.\n",
      "Class 21 22_Chromshpinelid contains 427 samples.\n",
      "Class 22 23_Cavorit contains 434 samples.\n",
      "Class 23 24_Shpinel contains 493 samples.\n",
      "mean=(0.498678951006717, 0.544194508079587, 0.3927654326966299), std=(0.20602235101817923, 0.2231311506315113, 0.16502139127714896)\n",
      "------------------------------------------------------------------\n",
      "undersamling...\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9617/9617 [00:09<00:00, 1063.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New size of any class 304 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7296/7296 [00:06<00:00, 1140.79it/s]\n",
      "100%|██████████| 7296/7296 [00:07<00:00, 1028.58it/s]\n",
      "100%|██████████| 7296/7296 [00:07<00:00, 945.86it/s] \n",
      "100%|██████████| 7296/7296 [00:06<00:00, 1052.15it/s]\n",
      " 58%|█████▊    | 4255/7296 [02:12<01:34, 32.07it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m prepare_dataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNew_dataset_small\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn [2], line 38\u001B[0m, in \u001B[0;36mprepare_dataset\u001B[0;34m(dataset, check)\u001B[0m\n\u001B[1;32m     36\u001B[0m folds \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m---> 38\u001B[0m     f1, f2 \u001B[38;5;241m=\u001B[39m \u001B[43msplit_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m     folds\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39marray([ds\u001B[38;5;241m.\u001B[39mindices[f1], ds\u001B[38;5;241m.\u001B[39mindices[f2]]))\n\u001B[1;32m     40\u001B[0m folds \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(folds)\n",
      "File \u001B[0;32m~/workspace/Fedot.Industrial/core/architecture/datasets/splitters.py:58\u001B[0m, in \u001B[0;36msplit_data\u001B[0;34m(dataset, n, verbose)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msplit_data\u001B[39m(dataset: Dataset, n: \u001B[38;5;28mint\u001B[39m, verbose: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m    Splits the data into n parts, keeping the proportions of the classes.\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m        A list of indices for each part.\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m     classes_of_imgs \u001B[38;5;241m=\u001B[39m \u001B[43mextract_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m     classes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(classes_of_imgs)\n\u001B[1;32m     60\u001B[0m     fold_indices \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n)]\n",
      "File \u001B[0;32m~/workspace/Fedot.Industrial/core/architecture/datasets/splitters.py:114\u001B[0m, in \u001B[0;36mextract_classes\u001B[0;34m(dataset)\u001B[0m\n\u001B[1;32m    112\u001B[0m classes_of_imgs \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(dataset))):\n\u001B[0;32m--> 114\u001B[0m     img, target \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    115\u001B[0m     classes_of_imgs\u001B[38;5;241m.\u001B[39mappend(target)\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(classes_of_imgs)\n",
      "File \u001B[0;32m~/workspace/Fedot.Industrial/venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[0;32m--> 295\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/workspace/Fedot.Industrial/venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:231\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    229\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader(path)\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 231\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[0;32m~/workspace/Fedot.Industrial/venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:135\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/Fedot.Industrial/venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:169\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    167\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mview(pic\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m1\u001B[39m], pic\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlen\u001B[39m(pic\u001B[38;5;241m.\u001B[39mgetbands()))\n\u001B[1;32m    168\u001B[0m \u001B[38;5;66;03m# put it from HWC to CHW format\u001B[39;00m\n\u001B[0;32m--> 169\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpermute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontiguous\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\u001B[38;5;241m.\u001B[39mto(dtype\u001B[38;5;241m=\u001B[39mdefault_float_dtype)\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "prepare_dataset('New_dataset_small')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
